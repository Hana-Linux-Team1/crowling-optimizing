{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e01199-aa33-4813-a3dc-40ee838923c1",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad10bbd-dedd-44b8-8781-9abeed79490d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: 이동식 행거\n",
      "가격: 가격 없음\n",
      "설명: 바퀴가 있어 이동하는데 여자인 저 혼자도 충분히 옮기는데 무리없었어요. 튼튼하고 편하게 잘 썼는데 이사때문에 나눔하려구요.\n",
      "위치: 강동구 천호동\n",
      "이미지 url:  https://dnvefa72aowie.cloudfront.net/origin/article/202406/812149e509474f644e62a455b495f2ccd4e990634dcc5b34e1dc49664697cc98_0.webp?f=webp&q=95&s=1440x1440&t=inside\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "p_num = 780003799\n",
    "url = 'https://www.daangn.com/articles/780003788'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 페이지 요청\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# 요청이 성공적인지 확인\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 제목 추출\n",
    "    title_tag = soup.find('h1', class_='hide')\n",
    "    title = title_tag.get_text(strip=True) if title_tag else '제목 없음'\n",
    "\n",
    "    # 가격 추출\n",
    "    price_tag = soup.find('p', id='article-price')\n",
    "    price = price_tag.get_text(strip=True) if price_tag else '가격 없음'\n",
    "    \n",
    "    # 설명 추출\n",
    "    description_tag = soup.find('div', id='article-detail')\n",
    "    description = ''\n",
    "    if description_tag:\n",
    "        for br in description_tag.find_all('br'):\n",
    "            br.replace_with('\\n')\n",
    "        description = description_tag.get_text(strip=True)\n",
    "    else:\n",
    "        description ='설명 없음'\n",
    "    \n",
    "    # 이미지 추출\n",
    "    \n",
    "    img_url = soup.find('div', class_='image-wrap').find('img')['data-lazy']\n",
    "    # os.system(\"curl \" + img_url + \" > test.jpg\")\n",
    "    # img = Image.open(\"test.jpg\")\n",
    "#     if img_tag:\n",
    "#         img_link = img_tag.find('img')['src']\n",
    "#         os.system(\"curl \" + url + \" > test.jpg\")\n",
    "        \n",
    "#         # 저장 된 이미지 확인\n",
    "#         img = Image.open(\"test.jpg\")\n",
    "#     else:\n",
    "#         img_link = '링크 없음'\n",
    "        \n",
    "    # 위치 추출\n",
    "    location_tag = soup.find('div', id='region-name')\n",
    "    location = location_tag.get_text(strip=True) if location_tag else '위치 없음'\n",
    "\n",
    "    # 추출된 데이터 출력\n",
    "    print('제목:', title)\n",
    "    print('가격:', price)\n",
    "    print('설명:', description)\n",
    "    print('위치:', location)\n",
    "    \n",
    "    print('이미지 url: ',img_url)\n",
    "\n",
    "else:\n",
    "    print('페이지 요청에 실패했습니다. 상태 코드:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4398d6-8674-4b25-95ec-e57197cec1e8",
   "metadata": {},
   "source": [
    "## crawling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21ff0e-6385-4640-aedd-3219e5447223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Queue, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abec8f7-92cd-45ee-9aae-6bb148008da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def karrot_crawling(p_num):\n",
    "    url = 'https://www.daangn.com/articles/'+str(p_num)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    # file = open('./crawling.txt','w')\n",
    "    # 페이지 요청\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # 요청이 성공적인지 확인\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 제목 추출\n",
    "        title_tag = soup.find('h1', class_='hide')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else '제목 없음'\n",
    "\n",
    "        # 가격 추출\n",
    "        price_tag = soup.find('p', id='article-price')\n",
    "        price = price_tag.get_text(strip=True) if price_tag else '가격 없음'\n",
    "\n",
    "        # 설명 추출\n",
    "        description_tag = soup.find('div', id='article-detail')\n",
    "        description = ''\n",
    "        if description_tag:\n",
    "            for br in description_tag.find_all('br'):\n",
    "                br.replace_with('\\n')\n",
    "            description = description_tag.get_text(strip=True)\n",
    "        else:\n",
    "            description ='설명 없음'\n",
    "        \n",
    "        # 이미지 url 추출\n",
    "        try:\n",
    "            img_url = soup.find('div', class_='image-wrap').find('img')['data-lazy']\n",
    "        except:\n",
    "            img_url = '이미지 없음'\n",
    "        # img_url = img_url_tag.get_text(strip=True) if img_url_tag else 'url 없음'\n",
    "        \n",
    "        # 위치 추출\n",
    "        location_tag = soup.find('div', id='region-name')\n",
    "        location = location_tag.get_text(strip=True) if location_tag else '위치 없음'\n",
    "\n",
    "        # 추출된 데이터 출력\n",
    "        print('제목:', title)\n",
    "        print('가격:', price)\n",
    "        print('설명:', description)\n",
    "        print('위치:', location)\n",
    "        print('이미지 url', img_url)\n",
    "        print('============================================================\\n')\n",
    "        \n",
    "        # file.write('제목:'+ title+'\\n')\n",
    "        # file.write('가격:'+ price+'\\n')\n",
    "        # file.write('설명:'+ description+'\\n')\n",
    "        # file.write('위치:'+ location+'\\n')\n",
    "        # file.write('이미지 url'+img_url+'\\n')\n",
    "        # file.write('============================================================\\n')\n",
    "\n",
    "    else:\n",
    "        print('페이지 요청에 실패했습니다. 상태 코드:', response.status_code)\n",
    "    # file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943c1ba-e78a-4899-8960-8bb2608e6df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/gimjuhwan/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'karrot_crawling' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    p_num = 780003799\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 크롤링할 페이지 번호 리스트 생성\n",
    "    page_numbers = [p_num + i for i in range(10)]\n",
    "\n",
    "    # 멀티프로세싱 풀 생성\n",
    "    with Pool(processes=4) as pool:  # 프로세스 수 조절 가능\n",
    "        pool.map(karrot_crawling, page_numbers)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"총 소요 시간: \", round(end_time - start_time, 4), \" 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f2a7a-99e0-406c-8fef-059c64beed55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
